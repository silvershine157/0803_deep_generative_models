{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generative Adversarial Network (GAN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generative Adversarial Networks (GANs)는 가짜 데이터를 생성하는 generator와 진짜와 가짜를 구분하는 discriminator를 경쟁시키는 방식으로 generator를 학습시키는 방법입니다.\n",
    "\n",
    "이번 실습에서는 숫자 이미지 데이터셋 MNIST에 간단한 GAN을 학습시켜 보겠습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "필요한 라이브러리를 임포트해줍니다. 이 노트북은 tensorflow 1.14 기준으로 작성되었기에 eager execution을 명시적으로 켜주겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from IPython import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import os\n",
    "#os.environ['CUDA_VISIBLE_DEVICES'] = '1'\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "tf.enable_eager_execution()\n",
    "print(tf.__version__)\n",
    "print(tf.test.is_gpu_available())\n",
    "print(tf.executing_eagerly())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MNIST 데이터를 가져옵시다. 여기서는 label이 필요하지 않으며, train set만 사용하겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 256\n",
    "(images, _), (_, _) = tf.keras.datasets.mnist.load_data() # (60000, 28, 28)\n",
    "images = images.reshape(images.shape[0], 28, 28, 1).astype('float32') # (60000, 28, 28, 1)\n",
    "images = (images-127.5)/127.5\n",
    "dataset = tf.data.Dataset.from_tensor_slices(images).shuffle(images.shape[0]).batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "로드한 MNIST 이미지 중 몇장을 시각화해봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_batch(images):\n",
    "    M = 4\n",
    "    fig = plt.figure(figsize=(M,M))\n",
    "    for i in range(M*M):\n",
    "        plt.subplot(M, M, i+1)\n",
    "        plt.imshow(images[i, :, :, 0]*127.5+127.5, cmap='gray')\n",
    "        plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for real_image in dataset:\n",
    "    break\n",
    "visualize_batch(real_image.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generator\n",
    "\n",
    "Generator는 (B, 100)크기의 노이즈를 input으로 하고, (B, 28, 28, 1) 크기의 흑백 이미지를 output으로 하는 신경망입니다. Keras layers를 이용하여 구현하겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NOISE_DIM = 100\n",
    "\n",
    "def make_generator_model(verbose=False):\n",
    "    \n",
    "    model = tf.keras.Sequential()\n",
    "    \n",
    "    # FC & reshape\n",
    "    model.add(layers.Dense(7*7*256, use_bias=False, input_shape=(NOISE_DIM,)))\n",
    "    if verbose:\n",
    "        print(model.output_shape)\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU())\n",
    "    \n",
    "    model.add(layers.Reshape((7, 7, 256)))\n",
    "    if verbose:\n",
    "        print(model.output_shape)\n",
    "    \n",
    "    # ConvTrans1\n",
    "    model.add(layers.Conv2DTranspose(128, (5, 5), strides=(1, 1), padding='same', use_bias=False))\n",
    "    if verbose:\n",
    "        print(model.output_shape)\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU())\n",
    "    \n",
    "    # ConvTrans2\n",
    "    model.add(layers.Conv2DTranspose(64, (5, 5), strides=(2, 2), padding='same', use_bias=False))\n",
    "    if verbose:\n",
    "        print(model.output_shape)\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU())\n",
    "    \n",
    "    # ConvTrans3\n",
    "    model.add(layers.Conv2DTranspose(1, (5, 5), strides=(2, 2), padding='same', use_bias=False, activation='tanh'))\n",
    "    if verbose:\n",
    "        print(model.output_shape)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test1():\n",
    "    gen_net = make_generator_model(verbose=True)\n",
    "test1()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discriminator\n",
    "\n",
    "Discriminator는 (B, 28, 28, 1) 크기의 흑백 이미지를 input으로 하고 (B, 1) 크기의 판단 결과를 output으로 하는 신경망입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_discriminator_model(verbose=False):\n",
    "    \n",
    "    model = tf.keras.Sequential()\n",
    "    \n",
    "    # Conv1\n",
    "    model.add(layers.Conv2D(64, (5, 5), strides=(2, 2), padding='same', input_shape=[28, 28, 1]))\n",
    "    if verbose: print(model.output_shape)\n",
    "    model.add(layers.LeakyReLU())\n",
    "    model.add(layers.Dropout(0.3))\n",
    "    \n",
    "    # Conv2\n",
    "    model.add(layers.Conv2D(128, (5, 5), strides=(2, 2), padding='same'))\n",
    "    if verbose: print(model.output_shape)\n",
    "    model.add(layers.LeakyReLU())\n",
    "    model.add(layers.Dropout(0.3))\n",
    "    \n",
    "    # reshape & FC\n",
    "    model.add(layers.Flatten())\n",
    "    if verbose: print(model.output_shape)\n",
    "    \n",
    "    model.add(layers.Dense(1))\n",
    "    if verbose: print(model.output_shape)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test2():\n",
    "    disc_net = make_discriminator_model(verbose=True)\n",
    "test2()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "트레이닝 되지 않은 generator와 discriminator로 이미지를 생성하고, 평가해봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test3():\n",
    "    gen_net = make_generator_model()\n",
    "    disc_net = make_discriminator_model()\n",
    "    noise = tf.random.normal([BATCH_SIZE, NOISE_DIM])\n",
    "    fake_images = gen_net(noise, training=False)\n",
    "    visualize_batch(fake_images.numpy())\n",
    "    fake_d_out = disc_net(fake_images)\n",
    "    print(fake_d_out.shape)\n",
    "test3()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "한 epoch에 대한 트레이닝 루틴입니다. Discriminator는 real image에 대해서는 1으로 평가하도록, fake image에 대해서는 0으로 평가하도록 학습해야합니다. Generator는 자신이 생성한 fake image가 discriminator에 의해 1에 가까운 평가를 받도록 학습해야합니다. 이 의도에 맞는 loss를 구현해줍니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "SKIP_GEN_ITERS = 1\n",
    "SKIP_DISC_ITERS = 1\n",
    "def train_epoch(gen_net, disc_net, gen_opt, disc_opt, dataset):\n",
    "    gen_loss_sum = 0.0\n",
    "    real_disc_loss_sum = 0.0\n",
    "    fake_disc_loss_sum = 0.0\n",
    "    gen_cnt = 0\n",
    "    disc_cnt = 0\n",
    "    for batch_idx, real_image in enumerate(dataset):\n",
    "        skip_gen = (batch_idx%SKIP_GEN_ITERS != 0)\n",
    "        skip_disc = (batch_idx%SKIP_DISC_ITERS != 0)\n",
    "        noise = tf.random.normal([BATCH_SIZE, NOISE_DIM])\n",
    "        with tf.GradientTape() as disc_tape, tf.GradientTape() as gen_tape:\n",
    "            fake_image = gen_net(noise, training=True)\n",
    "            real_d_out = disc_net(real_image, training=True)\n",
    "            fake_d_out = disc_net(fake_image, training=True)\n",
    "            \n",
    "            # compute loss\n",
    "            if not skip_disc:\n",
    "                real_disc_loss = cross_entropy(tf.ones_like(real_d_out), real_d_out)\n",
    "                fake_disc_loss = cross_entropy(tf.zeros_like(fake_d_out), fake_d_out)\n",
    "                disc_loss = real_disc_loss + fake_disc_loss\n",
    "            if not skip_gen:\n",
    "                gen_loss = cross_entropy(tf.ones_like(fake_d_out), fake_d_out)\n",
    "\n",
    "        if not skip_gen:\n",
    "            gen_grad = gen_tape.gradient(gen_loss, gen_net.trainable_variables)\n",
    "            gen_opt.apply_gradients(zip(gen_grad, gen_net.trainable_variables))\n",
    "        if not skip_disc:\n",
    "            disc_grad = disc_tape.gradient(disc_loss, disc_net.trainable_variables)\n",
    "            disc_opt.apply_gradients(zip(disc_grad, disc_net.trainable_variables))\n",
    "\n",
    "        if not skip_gen:\n",
    "            gen_loss_sum += gen_loss.numpy()\n",
    "            gen_cnt += 1\n",
    "        if not skip_disc:\n",
    "            real_disc_loss_sum += real_disc_loss.numpy()\n",
    "            fake_disc_loss_sum += fake_disc_loss.numpy()\n",
    "            disc_cnt += 1\n",
    "    gen_loss_epoch = gen_loss_sum/gen_cnt\n",
    "    real_disc_loss_epoch = real_disc_loss_sum/disc_cnt\n",
    "    fake_disc_loss_epoch = fake_disc_loss_sum/disc_cnt\n",
    "    return gen_loss_epoch, real_disc_loss_epoch, fake_disc_loss_epoch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "학습을 초기화합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_opt = tf.keras.optimizers.Adam(1e-4)\n",
    "disc_opt = tf.keras.optimizers.Adam(1e-4)\n",
    "gen_net = make_generator_model()\n",
    "disc_net = make_discriminator_model()\n",
    "sample_noise = tf.random.normal([BATCH_SIZE, NOISE_DIM])\n",
    "gen_loss_history = []\n",
    "real_disc_loss_history = []\n",
    "fake_disc_loss_history = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "학습을 진행하고, 일정한 noise input에 대한 generator sample의 변화를 관찰해봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 50\n",
    "for epoch in range(1, n_epochs+1):\n",
    "    gen_loss, real_disc_loss, fake_disc_loss = train_epoch(gen_net, disc_net, gen_opt, disc_opt, dataset)\n",
    "    sample_image = gen_net(sample_noise, training=False)\n",
    "    gen_loss_history.append(gen_loss)\n",
    "    real_disc_loss_history.append(real_disc_loss)\n",
    "    fake_disc_loss_history.append(fake_disc_loss)\n",
    "    display.clear_output(wait=True)\n",
    "    print('< Epoch {:d} >'.format(epoch))\n",
    "    visualize_batch(sample_image.numpy())\n",
    "    if len(gen_loss_history) >= 2:\n",
    "        plt.plot(gen_loss_history, label='gen loss')\n",
    "        plt.plot(real_disc_loss_history, label='real disc loss')\n",
    "        plt.plot(fake_disc_loss_history, label='fake disc loss')\n",
    "        plt.legend()\n",
    "        plt.xlabel('epoch')\n",
    "        plt.show()\n",
    "    print('gen loss: ', gen_loss)\n",
    "    print('fake disc loss: ', fake_disc_loss)\n",
    "    print('real disc loss: ', real_disc_loss)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "p36",
   "language": "python",
   "name": "p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
