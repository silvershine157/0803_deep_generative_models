{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generative Adversarial Network (GAN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generative Adversarial Networks (GANs)는 가짜 데이터를 생성하는 generator와 진짜와 가짜를 구분하는 discriminator를 경쟁시키는 방식으로 학습시키는 생성모델입니다.\n",
    "\n",
    "이번 실습에서는 숫자 이미지 데이터셋 MNIST에 간단한 GAN을 학습시켜 보겠습니다.\n",
    "\n",
    "<img src=\"images/gan_mnist.png\" alt=\"Drawing\" style=\"width: 800px;\"/>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "필요한 라이브러리를 임포트해줍니다. 이 노트북은 tensorflow 1.14 기준으로 작성되었기에 eager execution을 명시적으로 켜주겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from IPython import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1'\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.enable_eager_execution()\n",
    "\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "tf.keras.backend.set_session(tf.Session(config=config))\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "print(tf.__version__)\n",
    "print(tf.test.is_gpu_available())\n",
    "print(tf.executing_eagerly())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MNIST 데이터를 가져옵시다. 여기서는 label이 필요하지 않으며, train set만 사용하겠습니다. 또한, 현재 0에서 255인 픽셀값이 -1에서 1의 범위를 가지도록 정규화를 해주겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 256\n",
    "(images, _), (_, _) = tf.keras.datasets.mnist.load_data() # (60000, 28, 28)\n",
    "images = images.reshape(images.shape[0], 28, 28, 1).astype('float32') # (60000, 28, 28, 1)\n",
    "images = (images-127.5)/127.5\n",
    "dataset = tf.data.Dataset.from_tensor_slices(images).shuffle(images.shape[0]).batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "로드한 MNIST 이미지 중 몇장을 시각화해봅시다. 같은 숫자라도 다양한 스타일로 적혀있는 것을 확인할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_batch(images):\n",
    "    M = 4\n",
    "    fig = plt.figure(figsize=(M,M))\n",
    "    for i in range(M*M):\n",
    "        plt.subplot(M, M, i+1)\n",
    "        plt.imshow(images[i, :, :, 0]*127.5+127.5, cmap='gray')\n",
    "        plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for real_image in dataset:\n",
    "    break\n",
    "visualize_batch(real_image.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generator\n",
    "\n",
    "$ G: \\mathbb{R}^{100} \\rightarrow \\mathbb{R}^{28 \\times 28} $\n",
    "\n",
    "Generator는 노이즈로부터 가짜 데이터를 생성하는 역할을 합니다. 우리 모델에서는 노이즈의 차원을 100으로 하겠습니다.\n",
    "\n",
    "(B, 100)크기의 노이즈를 input으로 하고, (B, 28, 28, 1) 크기의 흑백 이미지를 output으로 하는 신경망을 Keras API를 이용하여 구현하겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NOISE_DIM = 100\n",
    "\n",
    "def make_generator_model(verbose=False):\n",
    "    \n",
    "    model = tf.keras.Sequential()\n",
    "    \n",
    "    # FC & reshape\n",
    "    model.add(layers.Dense(7*7*256, use_bias=False, input_shape=(NOISE_DIM,)))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU())\n",
    "    \n",
    "    model.add(layers.Reshape((7, 7, 256)))\n",
    "    if verbose:\n",
    "        print(model.output_shape)\n",
    "    \n",
    "    # ConvTrans1\n",
    "    model.add(layers.Conv2DTranspose(128, (5, 5), strides=(1, 1), padding='same', use_bias=False))\n",
    "    if verbose:\n",
    "        print(model.output_shape)\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU())\n",
    "    \n",
    "    # ConvTrans2\n",
    "    model.add(layers.Conv2DTranspose(64, (5, 5), strides=(2, 2), padding='same', use_bias=False))\n",
    "    if verbose:\n",
    "        print(model.output_shape)\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU())\n",
    "    \n",
    "    # ConvTrans3\n",
    "    model.add(layers.Conv2DTranspose(1, (5, 5), strides=(2, 2), padding='same', use_bias=False, activation='tanh'))\n",
    "    if verbose:\n",
    "        print(model.output_shape)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test1():\n",
    "    gen_net = make_generator_model(verbose=True)\n",
    "test1()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discriminator\n",
    "\n",
    "Discriminator는 주어진 input이 진짜인지 가짜인지 판단하는 역할을 합니다. 진짜는 1, 가짜면 0을 target으로 학습될 것입니다.\n",
    "\n",
    "$ D: \\mathbb{R}^{28 \\times 28} \\rightarrow [0, 1]$\n",
    "\n",
    "우리의 모델에서는, 맨 끝단의 sigmoid layer를 생략하고 범위제한이 없는 logit을 output으로 하겠습니다.\n",
    "\n",
    "(B, 28, 28, 1) 크기의 흑백 이미지를 input으로 하고 (B, 1) 크기의 판단 결과를 output으로 하는 신경망을 구현하겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_discriminator_model(verbose=False):\n",
    "    \n",
    "    model = tf.keras.Sequential()\n",
    "    \n",
    "    # Conv1\n",
    "    model.add(layers.Conv2D(64, (5, 5), strides=(2, 2), padding='same', input_shape=[28, 28, 1]))\n",
    "    if verbose: print(model.output_shape)\n",
    "    model.add(layers.LeakyReLU())\n",
    "    model.add(layers.Dropout(0.3))\n",
    "    \n",
    "    # Conv2\n",
    "    model.add(layers.Conv2D(128, (5, 5), strides=(2, 2), padding='same'))\n",
    "    if verbose: print(model.output_shape)\n",
    "    model.add(layers.LeakyReLU())\n",
    "    model.add(layers.Dropout(0.3))\n",
    "    \n",
    "    # reshape & FC\n",
    "    model.add(layers.Flatten())\n",
    "    if verbose: print(model.output_shape)\n",
    "    \n",
    "    model.add(layers.Dense(1))\n",
    "    if verbose: print(model.output_shape)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test2():\n",
    "    disc_net = make_discriminator_model(verbose=True)\n",
    "test2()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "트레이닝 되지 않은 generator와 discriminator로 이미지를 생성하고, 평가해봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test3():\n",
    "    gen_net = make_generator_model()\n",
    "    disc_net = make_discriminator_model()\n",
    "    noise = tf.random.normal([BATCH_SIZE, NOISE_DIM])\n",
    "    fake_images = gen_net(noise, training=False)\n",
    "    visualize_batch(fake_images.numpy())\n",
    "    fake_d_out = disc_net(fake_images)\n",
    "    print(fake_d_out.shape)\n",
    "test3()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "한 iteration에 대한 트레이닝 루틴을 구현해봅시다. Discriminator는 real image에 대해서는 1으로 평가하도록, fake image에 대해서는 0으로 평가하도록 학습해야합니다. Generator는 자신이 생성한 fake image가 discriminator에 의해 1에 가까운 평가를 받도록 학습해야합니다. 이 의도에 맞게 loss를 설계하면 다음과 같습니다.\n",
    "\n",
    "$ \\textrm{discriminator loss} = \\mathbb{E}_{x \\sim \\textrm{data}}[- \\log (D(x))] + \\mathbb{E}_{z \\sim \\textrm{noise}}[- \\log (1 - D(G(z)))]$\n",
    "\n",
    "$ \\textrm{generator loss} = \\mathbb{E}_{z \\sim \\textrm{noise}}[- \\log (D(G(z)))]$\n",
    "\n",
    "위 내용을 바탕으로 GAN의 loss term들을 구현해봅시다.\n",
    "\n",
    "(주의: disc_net의 output은 0-1사이 값이 아니라 sigmoid를 통과하지 않아 범위가 정해지지 않은 logit입니다.) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "\n",
    "@tf.function\n",
    "def train_iter(real_image, gen_net, disc_net, gen_opt, disc_opt, skip_gen=False, skip_disc=False):\n",
    "    with tf.GradientTape() as disc_tape, tf.GradientTape() as gen_tape:\n",
    "        # --------------------------------------------------------------\n",
    "        # TODO: implement GAN loss terms: gen_loss, real_disc_loss, fake_disc_loss\n",
    "        \n",
    "        \n",
    "        \n",
    "        gen_loss = None\n",
    "        real_disc_loss = None\n",
    "        fake_disc_loss = None\n",
    "        # --------------------------------------------------------------\n",
    "        disc_loss = real_disc_loss + fake_disc_loss\n",
    "    if not skip_gen:\n",
    "        gen_grad = gen_tape.gradient(gen_loss, gen_net.trainable_variables)\n",
    "        gen_opt.apply_gradients(zip(gen_grad, gen_net.trainable_variables))\n",
    "    if not skip_disc:\n",
    "        disc_grad = disc_tape.gradient(disc_loss, disc_net.trainable_variables)\n",
    "        disc_opt.apply_gradients(zip(disc_grad, disc_net.trainable_variables))\n",
    "    return gen_loss, real_disc_loss, fake_disc_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "한 epoch에 대한 트레이닝 루틴입니다. SKIP_GEN_ITERS, SKIP_DISC_ITERS를 통해 학습페이스를 조절할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SKIP_GEN_ITERS = 1\n",
    "SKIP_DISC_ITERS = 1\n",
    "def train_epoch(gen_net, disc_net, gen_opt, disc_opt, dataset):\n",
    "    gen_loss_sum = 0.0\n",
    "    real_disc_loss_sum = 0.0\n",
    "    fake_disc_loss_sum = 0.0\n",
    "    gen_cnt = 0\n",
    "    disc_cnt = 0\n",
    "    for batch_idx, real_image in enumerate(dataset):\n",
    "        skip_gen = (batch_idx%SKIP_GEN_ITERS != 0)\n",
    "        skip_disc = (batch_idx%SKIP_DISC_ITERS != 0)\n",
    "        gen_loss, real_disc_loss, fake_disc_loss = train_iter(\n",
    "            real_image, gen_net, disc_net, gen_opt, disc_opt, skip_gen, skip_disc)\n",
    "        if not skip_gen:\n",
    "            gen_loss_sum += gen_loss.numpy()\n",
    "            gen_cnt += 1\n",
    "        if not skip_disc:\n",
    "            real_disc_loss_sum += real_disc_loss.numpy()\n",
    "            fake_disc_loss_sum += fake_disc_loss.numpy()\n",
    "            disc_cnt += 1\n",
    "    gen_loss_epoch = gen_loss_sum/gen_cnt\n",
    "    real_disc_loss_epoch = real_disc_loss_sum/disc_cnt\n",
    "    fake_disc_loss_epoch = fake_disc_loss_sum/disc_cnt\n",
    "    return gen_loss_epoch, real_disc_loss_epoch, fake_disc_loss_epoch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "학습을 초기화합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_opt = tf.keras.optimizers.Adam(1e-4)\n",
    "disc_opt = tf.keras.optimizers.Adam(1e-4)\n",
    "gen_net = make_generator_model()\n",
    "disc_net = make_discriminator_model()\n",
    "sample_noise = tf.random.normal([BATCH_SIZE, NOISE_DIM])\n",
    "gen_loss_history = []\n",
    "real_disc_loss_history = []\n",
    "fake_disc_loss_history = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "학습을 진행하고, 일정한 noise input에 대한 generator sample의 변화를 관찰해봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 50\n",
    "for epoch in range(1, n_epochs+1):\n",
    "    gen_loss, real_disc_loss, fake_disc_loss = train_epoch(gen_net, disc_net, gen_opt, disc_opt, dataset)\n",
    "    sample_image = gen_net(sample_noise, training=False)\n",
    "    gen_loss_history.append(gen_loss)\n",
    "    real_disc_loss_history.append(real_disc_loss)\n",
    "    fake_disc_loss_history.append(fake_disc_loss)\n",
    "    display.clear_output(wait=True)\n",
    "    print('< Epoch {:d} >'.format(epoch))\n",
    "    visualize_batch(sample_image.numpy())\n",
    "    if len(gen_loss_history) >= 2:\n",
    "        plt.plot(gen_loss_history, label='gen loss')\n",
    "        plt.plot(real_disc_loss_history, label='real disc loss')\n",
    "        plt.plot(fake_disc_loss_history, label='fake disc loss')\n",
    "        plt.legend()\n",
    "        plt.xlabel('epoch')\n",
    "        plt.show()\n",
    "    print('gen loss: ', gen_loss)\n",
    "    print('fake disc loss: ', fake_disc_loss)\n",
    "    print('real disc loss: ', real_disc_loss)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "p36",
   "language": "python",
   "name": "p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
